{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7126460,"sourceType":"datasetVersion","datasetId":4111042}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.models import Model\n\ndef mlp(x, cf):\n    x = L.Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n    x = L.Dropout(cf[\"dropout_rate\"])(x)\n    x = L.Dense(cf[\"hidden_dim\"])(x)\n    x = L.Dropout(cf[\"dropout_rate\"])(x)\n    return x\n\ndef transformer_encoder(x, cf):\n    skip_1 = x\n    x = L.LayerNormalization()(x)\n    x = L.MultiHeadAttention(\n        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n    )(x, x)\n    x = L.Add()([x, skip_1])\n\n    skip_2 = x\n    x = L.LayerNormalization()(x)\n    x = mlp(x, cf)\n    x = L.Add()([x, skip_2])\n\n    return x\n\ndef conv_block(x, num_filters, kernel_size=3):\n    x = L.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n    x = L.BatchNormalization()(x)\n    x = L.ReLU()(x)\n    return x\n\ndef deconv_block(x, num_filters):\n    x = L.Conv2DTranspose(num_filters, kernel_size=2, padding=\"same\", strides=2)(x)\n    return x\n\ndef build_unetr_2d(cf):\n    \"\"\" Inputs \"\"\"\n    input_shape = (cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"])\n    inputs = L.Input(input_shape)\n\n    # Resize the input image to the expected patch size\n    x = L.Reshape((cf[\"num_patches\"], cf[\"patch_size\"] * cf[\"patch_size\"] * cf[\"num_channels\"]))(inputs)\n    # x = L.Dense(cf[\"hidden_dim\"])(x)\n    \n    # \"\"\" Inputs \"\"\"\n    # input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n    # inputs = L.Input(input_shape) ## (None, 256, 768)\n\n    # \"\"\" Patch + Position Embeddings \"\"\"\n    patch_embed = L.Dense(cf[\"hidden_dim\"])(x) ## (None, 256, 768)\n\n    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1) ## (256,)\n    pos_embed = L.Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n    x = patch_embed + pos_embed ## (None, 256, 768)\n\n    \"\"\" Transformer Encoder \"\"\"\n    skip_connection_index = [3, 6, 9, 12]\n    skip_connections = []\n\n    for i in range(1, cf[\"num_layers\"]+1, 1):\n        x = transformer_encoder(x, cf)\n\n        if i in skip_connection_index:\n            skip_connections.append(x)\n\n    \"\"\" CNN Decoder \"\"\"\n    z3, z6, z9, z12 = skip_connections\n\n    ## Reshaping\n    z0 = L.Reshape((cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"]))(inputs)\n    z3 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z3)\n    z6 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z6)\n    z9 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z9)\n    z12 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z12)\n\n    ## Decoder 1\n    x = deconv_block(z12, 512)\n\n    s = deconv_block(z9, 512)\n    s = conv_block(s, 512)\n    x = L.Concatenate()([x, s])\n\n    x = conv_block(x, 512)\n    x = conv_block(x, 512)\n\n    ## Decoder 2\n    x = deconv_block(x, 256)\n\n    s = deconv_block(z6, 256)\n    s = conv_block(s, 256)\n    s = deconv_block(s, 256)\n    s = conv_block(s, 256)\n\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, 256)\n    x = conv_block(x, 256)\n\n    ## Decoder 3\n    x = deconv_block(x, 128)\n\n    s = deconv_block(z3, 128)\n    s = conv_block(s, 128)\n    s = deconv_block(s, 128)\n    s = conv_block(s, 128)\n    s = deconv_block(s, 128)\n    s = conv_block(s, 128)\n\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, 128)\n    x = conv_block(x, 128)\n\n    ## Decoder 4\n    x = deconv_block(x, 64)\n\n    s = conv_block(z0, 64)\n    s = conv_block(s, 64)\n\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, 64)\n    x = conv_block(x, 64)\n\n    \"\"\" Output \"\"\"\n    # outputs = L.Conv2D(11, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n    outputs = L.Conv2D(11, kernel_size=1, padding=\"same\", activation=\"softmax\")(x)\n\n\n    return Model(inputs, outputs, name=\"UNETR_2D\")\n\nif __name__ == \"__main__\":\n    config = {}\n    config[\"image_size\"] = 256\n    config[\"num_layers\"] = 12\n    config[\"hidden_dim\"] = 768\n    config[\"mlp_dim\"] = 3072\n    config[\"num_heads\"] = 12\n    config[\"dropout_rate\"] = 0.1\n    config[\"num_patches\"] = 256\n    config[\"patch_size\"] = 16\n    config[\"num_channels\"] = 3\n\n    model = build_unetr_2d(config)\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:49:24.761607Z","iopub.execute_input":"2023-12-05T05:49:24.761903Z","iopub.status.idle":"2023-12-05T05:49:45.007275Z","shell.execute_reply.started":"2023-12-05T05:49:24.761876Z","shell.execute_reply":"2023-12-05T05:49:45.005798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom glob import glob\nimport scipy.io\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n\n\n\n\"\"\" Global parameters \"\"\"\nglobal IMG_H\nglobal IMG_W\nglobal NUM_CLASSES\nglobal CLASSES\nglobal COLORMAP\n\n\"\"\" Creating a directory \"\"\"\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\"\"\" Load and split the dataset \"\"\"\ndef load_dataset(path, split=0.2):\n    images = sorted(glob(os.path.join(path, \"img_small_data\", \"*\")))[:1110]\n    masks = sorted(glob(os.path.join(path, \"mask_small_data\", \"*\")))[:1110]\n\n    split_size = int(split * len(images))\n\n    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\n\ndef get_colormap(path):\n    mat_path = os.path.join(path, \"multi_organ.mat\")\n    colormap = scipy.io.loadmat(mat_path)[\"multi_organ\"]\n\n    classes = [\n        \"Background\",\n        \"Spleen\",\n        \"Right kidney\",\n        \"Left kidney\",\n        \"Gallbladder\",\n        \"Liver\",\n        \"Stomach\",\n        \"Aorta\",\n        \"Inferior vena cava\",\n        \"Portal vein\",\n        \"pancreas\"\n    ]\n\n    return classes, colormap\n\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (IMG_W, IMG_H))\n    x = x.astype(np.float32)\n    return x\n\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (IMG_W, IMG_H))\n\n    #Masl processing\n    output=[]\n    # for i,color in enumerate(COLORMAP):\n    #   cmap = np.all(np.equal(x, color), axis=-1)\n    #   cv2.imwrite(f\"cmap{i}.png\", cmap*255)\n    for color in COLORMAP:\n      cmap = np.all(np.equal(x, color), axis=-1)\n      output.append(cmap)\n\n\n    output = np.stack(output, axis=-1)\n    output = output.astype(np.uint8)\n\n    return output\n\n\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        x =read_image(x)\n        y=read_mask(y)\n\n        return x,y\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.uint8])\n    image.set_shape([IMG_H, IMG_W, 3])\n    mask.set_shape([IMG_H, IMG_W, NUM_CLASSES])\n\n    return image, mask\n\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(2)\n    return dataset\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Directory for storing files \"\"\"\n    create_dir(\"files\")\n\n    \"\"\" Hyperparameters \"\"\"\n    IMG_H = 256\n    IMG_W = 256\n    NUM_CLASSES = 11\n#     input_shape = (IMG_H, IMG_W, 3)\n\n    batch_size = 6\n    lr = 1e-4\n    num_epochs = 60\n\n    config = {}\n    config[\"image_size\"] = 256\n    config[\"num_layers\"] = 12\n    config[\"hidden_dim\"] = 768\n    config[\"mlp_dim\"] = 3072\n    config[\"num_heads\"] = 12\n    config[\"dropout_rate\"] = 0.1\n    config[\"num_patches\"] = 256\n    config[\"patch_size\"] = 16\n    config[\"num_channels\"] = 3\n\n    dataset_path = \"/kaggle/input/small-data/small_data\"\n    model_path = os.path.join(\"files\", \"final_unter_model.h5\")\n    csv_path = os.path.join(\"files\", \"Unetr_Abdomen_data.csv\")\n\n    \"\"\" Loading the dataset \"\"\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n    print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_x)}\")\n\n    \"\"\" Process the colormap \"\"\"\n    CLASSES, COLORMAP = get_colormap(dataset_path)\n\n    print(\"COLOR:\",len(COLORMAP))\n\n    # read_mask(train_y[10])\n\n    \"\"\" Dataset Pipeline \"\"\"\n    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n\n    \"\"\" Model \"\"\"\n    model = build_unetr_2d(config)\n    # model.load_weights(model_path)\n    model.compile(\n        loss=\"categorical_crossentropy\",\n        optimizer=tf.keras.optimizers.Adam(lr)\n    )\n    # model.summary()\n\n    \"\"\" Training \"\"\"\n    callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path, append=True),\n        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n    ]\n\n    model.fit(train_dataset,\n        validation_data=valid_dataset,\n        epochs=num_epochs,\n        callbacks=callbacks\n    )\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:53:23.649074Z","iopub.execute_input":"2023-12-05T05:53:23.649677Z","iopub.status.idle":"2023-12-05T09:37:00.870802Z","shell.execute_reply.started":"2023-12-05T05:53:23.649646Z","shell.execute_reply":"2023-12-05T09:37:00.869857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\nimport scipy.io\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom PIL import Image\n# from train import load_dataset, create_dir, get_colormap\n\n\"\"\" Global parameters \"\"\"\nglobal IMG_H\nglobal IMG_W\nglobal NUM_CLASSES\nglobal CLASSES\nglobal COLORMAP\n\n\"\"\" Creating a directory \"\"\"\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\"\"\" Load and split the dataset \"\"\"\ndef load_dataset(path, split=0.2):\n    images = sorted(glob(os.path.join(path, \"img_small_data\", \"*\")))[:1110]\n    masks = sorted(glob(os.path.join(path, \"mask_small_data\", \"*\")))[:1110]\n\n    split_size = int(split * len(images))\n\n    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\n\ndef get_colormap(path):\n    mat_path = os.path.join(path, \"multi_organ.mat\")\n    colormap = scipy.io.loadmat(mat_path)[\"multi_organ\"]\n\n    classes = [\n        \"Background\",\n        \"Spleen\",\n        \"Right kidney\",\n        \"Left kidney\",\n        \"Gallbladder\",\n        \"Liver\",\n        \"Stomach\",\n        \"Aorta\",\n        \"Inferior vena cava\",\n        \"Portal vein\",\n        \"pancreas\"\n    ]\n\n    return classes, colormap\n\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (IMG_W, IMG_H))\n    x = x.astype(np.float32)\n    return x\n\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (IMG_W, IMG_H))\n\n    #Masl processing\n    output=[]\n    # for i,color in enumerate(COLORMAP):\n    #   cmap = np.all(np.equal(x, color), axis=-1)\n    #   cv2.imwrite(f\"cmap{i}.png\", cmap*255)\n    for color in COLORMAP:\n      cmap = np.all(np.equal(x, color), axis=-1)\n      output.append(cmap)\n\n\n    output = np.stack(output, axis=-1)\n    output = output.astype(np.uint8)\n\n    return output\n\n\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        x =read_image(x)\n        y=read_mask(y)\n\n        return x,y\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.uint8])\n    image.set_shape([IMG_H, IMG_W, 3])\n    mask.set_shape([IMG_H, IMG_W, NUM_CLASSES])\n\n    return image, mask\n\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(2)\n    return dataset\n\n\ndef grayscale_to_rgb(mask, classes, colormap):\n    h, w, _ = mask.shape\n    mask = mask.astype(np.int32)\n    output = []\n\n    for i, pixel in enumerate(mask.flatten()):\n        output.append(colormap[pixel])\n\n    output = np.reshape(output, (h, w, 3))\n    return output\n\ndef save_results(image, mask, pred, save_image_path):\n    # print(image.shape,mask.shape,pred.shape)\n    h, w, _ = image.shape\n    line = np.ones((h, 10, 3)) * 255\n\n    pred = np.expand_dims(pred, axis=-1)\n    pred = grayscale_to_rgb(pred, CLASSES, COLORMAP)\n\n    # Ensure both images have the same shape\n    assert image.shape == mask.shape, \"Images must have the same shape\"\n    assert image.shape == pred.shape\n\n    # Blend the images using the alpha parameter\n    alpha = 0.5\n    blended_image1 = alpha * image + (1 - alpha) * mask\n    blended_image2 = alpha * image + (1 - alpha) * pred\n    # alpha = 0.5\n    # blended_image1 = Image.blend(image, mask, alpha)\n    # blended_image2 = Image.blend(image, pred, alpha)\n\n    cat_images = np.concatenate([image, line, mask, line, pred, line, blended_image1, blended_image2], axis=1)\n    cv2.imwrite(save_image_path, cat_images)\n\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Directory for storing files \"\"\"\n    create_dir(\"files\")\n\n    \"\"\" Directory for storing files \"\"\"\n    create_dir(\"results2/predictions\")\n\n    \"\"\" Hyperparameters \"\"\"\n    IMG_H = 256\n    IMG_W = 256\n    NUM_CLASSES = 11\n    dataset_path = \"/kaggle/input/small-data/small_data\"\n    # dataset_path = \"/content/drive/MyDrive/human\"\n    # model_path = os.path.join(\"files\", \"model1.h5\")\n    model_path = \"/kaggle/working/files/final_unter_model.h5\"\n\n    \"\"\" Colormap \"\"\"\n    CLASSES, COLORMAP = get_colormap(dataset_path)\n\n    \"\"\" Model \"\"\"\n    model = tf.keras.models.load_model(model_path)\n    # model.summary()\n\n    \"\"\" Load the dataset \"\"\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n    print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_y)}\")\n    print(\"\")\n\n    # Prediction and Evaluation\n\n    SCORE = []\n    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n      name = x.split(\"/\")[-1].split(\".\")[0]\n\n      \"\"\" Reading the image \"\"\"\n      image = cv2.imread(x, cv2.IMREAD_COLOR)\n      image = cv2.resize(image, (IMG_W, IMG_H))\n      image_x = image\n      # image = image/255.0\n      image = np.expand_dims(image, axis=0)\n\n      \"\"\" Reading the mask \"\"\"\n      mask = cv2.imread(y, cv2.IMREAD_COLOR)\n      mask = cv2.resize(mask, (IMG_W, IMG_H))\n      mask_x = mask\n      onehot_mask = []\n      for color in COLORMAP:\n          cmap = np.all(np.equal(mask, color), axis=-1)\n          onehot_mask.append(cmap)\n      onehot_mask = np.stack(onehot_mask, axis=-1)\n      onehot_mask = np.argmax(onehot_mask, axis=-1)\n      onehot_mask = onehot_mask.astype(np.int32)\n\n      \"\"\" Prediction \"\"\"\n      pred = model.predict(image, verbose=0)[0]\n      pred = np.argmax(pred, axis=-1)\n      pred = pred.astype(np.float32)\n\n      \"\"\" Saving the prediction \"\"\"\n      save_image_path = f\"results2/predictions/{name}.png\"\n      save_results(image_x, mask_x, pred, save_image_path)\n\n      \"\"\" Flatten the array \"\"\"\n      onehot_mask = onehot_mask.flatten()\n      pred = pred.flatten()\n\n      labels = [i for i in range(NUM_CLASSES)]\n\n      \"\"\" Calculating the metrics values \"\"\"\n      f1_value = f1_score(onehot_mask, pred, labels=labels, average=None, zero_division=0)\n      jac_value = jaccard_score(onehot_mask, pred, labels=labels, average=None, zero_division=0)\n\n      SCORE.append([f1_value, jac_value])\n\n\n    # \"\"\" Metrics values \"\"\"\n    # score = np.array(SCORE)\n    # score = np.mean(score, axis=0)\n\n    # f = open(\"files/score.csv\", \"w\")\n    # f.write(\"Class,F1,Jaccard\\n\")\n\n    # l = [\"Class\", \"F1\", \"Jaccard\"]\n    # print(f\"{l[0]:15s} {l[1]:10s} {l[2]:10s}\")\n    # print(\"-\"*35)\n\n    # for i in range(score.shape[1]):\n    #     class_name = CLASSES[i]\n    #     f1 = score[0, i]\n    #     jac = score[1, i]\n    #     dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f}\"\n    #     print(dstr)\n    #     f.write(f\"{class_name:15s},{f1:1.5f},{jac:1.5f}\\n\")\n\n    # print(\"-\"*35)\n    # class_mean = np.mean(score, axis=-1)\n    # class_name = \"Mean\"\n    # f1 = class_mean[0]\n    # jac = class_mean[1]\n    # dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f}\"\n    # print(dstr)\n    # f.write(f\"{class_name:15s},{f1:1.5f},{jac:1.5f}\\n\")\n\n    # f.close()\n\n    \"\"\" Metrics values \"\"\"\n    score = np.array(SCORE)\n    score = np.mean(score, axis=0)\n\n    # Calculate accuracy using true labels and predicted labels\n    accuracy = accuracy_score(onehot_mask, pred.flatten())\n\n    f = open(\"files/score.csv\", \"w\")\n    f.write(\"Class,F1,Jaccard,Accuracy\\n\")\n\n    l = [\"Class\", \"F1\", \"Jaccard\", \"Accuracy\"]\n    print(f\"{l[0]:15s} {l[1]:10s} {l[2]:10s} {l[3]:10s}\")\n    print(\"-\" * 50)\n\n    for i in range(score.shape[1]):\n        class_name = CLASSES[i]\n        f1 = score[0, i]\n        jac = score[1, i]\n        dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f} - {accuracy:1.5f}\"\n        print(dstr)\n        f.write(f\"{class_name:15s},{f1:1.5f},{jac:1.5f},{accuracy:1.5f}\\n\")\n\n    print(\"-\" * 50)\n    class_mean = np.mean(score, axis=-1)\n    class_name = \"Mean\"\n    f1 = class_mean[0]\n    jac = class_mean[1]\n    dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f} - {accuracy:1.5f}\"\n    print(dstr)\n    f.write(f\"{class_name:15s},{f1:1.5f},{jac:1.5f},{accuracy:1.5f}\\n\")\n\n    f.close()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:52:00.338960Z","iopub.execute_input":"2023-12-05T09:52:00.339358Z","iopub.status.idle":"2023-12-05T09:53:33.318687Z","shell.execute_reply.started":"2023-12-05T09:52:00.339329Z","shell.execute_reply":"2023-12-05T09:53:33.317694Z"},"trusted":true},"execution_count":null,"outputs":[]}]}